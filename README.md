# Advanced Human Language Technologies (AHLT)

[![Python](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

This repository contains implementations for biomedical Natural Language Processing tasks, developed as part of the Advanced Human Language Technologies course at UPC (Universitat PolitÃ¨cnica de Catalunya).

## ğŸ¯ Overview

The project focuses on three core biomedical NLP tasks:

- **Named Entity Recognition (NER)**: Drug name identification and classification
- **Drug-Drug Interaction (DDI) Detection**: Identifying pharmacological interactions between drug entities
- **Neural Networks**: Deep learning approaches for both NER and DDI classification

## ğŸš€ Quick Start

### Prerequisites

- Python 3.7+
- Java 8+ (for CoreNLP server, DDI tasks only)

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd ahlt-1
```

2. Install Python dependencies:
```bash
pip install -r requirements.txt
```

3. Download NLTK data (first time only):
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
```

4. **For DDI tasks only**: Set up CoreNLP server:
```bash
# Download Stanford CoreNLP from https://stanfordnlp.github.io/CoreNLP/
# Extract and run:
java -mx4g -cp "*" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000
```

## ğŸ“Š Usage

### Named Entity Recognition (NER)

#### Baseline NER (Rule-based)
```bash
cd "1. NER"

# Basic usage
python3 baseline-NER.py train_data_path output_file_name

# With drug database lookup
python3 baseline-NER.py -l train_data_path output_file_name
```

#### CRF-based NER
```bash
cd "1. NER"

# Extract features
python3 feature_extractor.py train_data_path > features_train.txt
python3 feature_extractor.py test_data_path > features_test.txt

# Train CRF model
python3 crf-learner.py model_name features_train.txt

# Run classification
python3 crf-classifier.py model_name features_test.txt entities_file output_file
```

### Drug-Drug Interaction (DDI) Detection

#### Complete Pipeline (Recommended)
```bash
cd "2. DDI"
bash runner.sh
```

#### Manual Steps
```bash
cd "2. DDI"

# Extract features
python3 feature_extractor.py ../../labAHLT/data/train > feats.dat
python3 feature_extractor.py ../../labAHLT/data/test > feats_test.dat

# Train and classify
python3 learner.py feats.dat feats_test.dat output.dat

# Evaluate
python3 evaluator.py DDI ../../labAHLT/data/test output.dat
```

### Evaluation

```bash
# Evaluate NER results
python3 "1. NER/evaluator.py" NER gold_standard_dir predictions_file

# Evaluate DDI results
python3 evaluator.py DDI gold_standard_dir predictions_file
```

## ğŸ“ Project Structure

```
ahlt-1/
â”œâ”€â”€ 1. NER/                    # Named Entity Recognition
â”‚   â”œâ”€â”€ baseline-NER.py        # Rule-based NER implementation
â”‚   â”œâ”€â”€ crf-classifier.py      # CRF-based classifier
â”‚   â”œâ”€â”€ crf-learner.py         # CRF model training
â”‚   â”œâ”€â”€ feature_extractor.py   # Feature engineering
â”‚   â”œâ”€â”€ evaluator.py           # Evaluation metrics
â”‚   â”œâ”€â”€ utils.py               # Utility functions
â”‚   â””â”€â”€ *.ipynb                # Jupyter notebooks for experimentation
â”œâ”€â”€ 2. DDI/                    # Drug-Drug Interaction Detection
â”‚   â”œâ”€â”€ baseline-DDI.py        # Rule-based DDI detection
â”‚   â”œâ”€â”€ feature_extractor.py   # DDI feature extraction
â”‚   â”œâ”€â”€ learner.py             # ML model training
â”‚   â”œâ”€â”€ runner.sh              # Complete pipeline script
â”‚   â”œâ”€â”€ utils.py               # DDI utilities
â”‚   â””â”€â”€ *.ipynb                # Analysis notebooks
â”œâ”€â”€ 3. NN/                     # Neural Network implementations
â”‚   â”œâ”€â”€ *.nn                   # Pre-trained models
â”‚   â”œâ”€â”€ *.txt                  # Data splits
â”‚   â””â”€â”€ *.ipynb                # NN experimentation notebooks
â”œâ”€â”€ resources/                 # Drug databases
â”‚   â”œâ”€â”€ HSDB.txt               # Simple drug database
â”‚   â””â”€â”€ DrugBank.txt           # Comprehensive drug database
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€README.md                  # This file
```

## ğŸ”§ Technical Details

### Data Format

- **Input**: XML files with sentence-level annotations
- **Entities**: Marked with `charOffset`, `text`, and `type` attributes
- **DDI Pairs**: Entity pairs with interaction classifications
- **Features**: Tab-separated feature vectors for ML training

### Key Dependencies

- **NLTK**: Natural language processing toolkit
- **python-crfsuite**: Conditional Random Fields implementation
- **scikit-learn**: Machine learning library
- **networkx**: Graph algorithms for dependency parsing
- **Stanford CoreNLP**: Dependency parsing (external server)

### Drug Databases

- `HSDB.txt`: Simple drug name database
- `DrugBank.txt`: Comprehensive database with categories (drug|brand|group)

## ğŸ“ˆ Performance

The implementations include several approaches with varying performance characteristics:

- **Rule-based methods**: Fast, interpretable, good baseline performance
- **CRF models**: Better sequence modeling, improved NER accuracy
- **Neural networks**: State-of-the-art performance on both tasks
- **Feature engineering**: Syntactic and semantic features for DDI detection

## ğŸ¤ Contributing

This is an academic project for the AHLT course. For development guidelines and technical details, see `CLAUDE.md`.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ« Academic Context

**Course**: Advanced Human Language Technologies  
**Institution**: Universitat PolitÃ¨cnica de Catalunya (UPC)  
**Focus**: Biomedical Natural Language Processing

